#!/usr/bin/env python3

from sub_convert import sub_convert # Python ä¹‹é—´äº’ç›¸è°ƒç”¨æ–‡ä»¶https://blog.csdn.net/winycg/article/details/78512300
from list_update import update_url

import json, re
from urllib import request


# åˆ†æå½“å‰é¡¹ç›®ä¾èµ– https://blog.csdn.net/lovedingd/article/details/102522094


# æ–‡ä»¶è·¯å¾„å®šä¹‰
Eterniy = './Eternity'
readme = './README.md'

sub_list_json = './sub/sub_list.json'
sub_merge_path = './sub/'
sub_list_path = './sub/list/'

class sub_merge():
    def sub_merge(url_list): # å°†è½¬æ¢åçš„æ‰€æœ‰ Url é“¾æ¥å†…å®¹åˆå¹¶è½¬æ¢ YAML or Base64, ï¼Œå¹¶è¾“å‡ºæ–‡ä»¶ï¼Œè¾“å…¥è®¢é˜…åˆ—è¡¨ã€‚

        content_list = []
        for index in range(len(url_list)):
            content = sub_convert.convert_remote(url_list[index]['url'],'url')
            ids = url_list[index]['id']
            remarks = url_list[index]['remarks']
            #try:
            if content == 'Url è§£æé”™è¯¯':
                content = sub_convert.convert(sub_merge.read_list(sub_list_json)[index]['url'],'url','url')
                if content != 'Url è§£æé”™è¯¯':
                    content_list.append(content)
                    print(f'Writing content of {remarks} to {ids:0>2d}.txt\n')
                else:
                    print(f'Writing error of {remarks} to {ids:0>2d}.txt\n')
                file = open(f'{sub_list_path}{ids:0>2d}.txt', 'w', encoding= 'utf-8')
                file.write('Url è§£æé”™è¯¯')
                file.close()
            elif content == 'Url è®¢é˜…å†…å®¹æ— æ³•è§£æ':
                file = open(f'{sub_list_path}{ids:0>2d}.txt', 'w', encoding= 'utf-8')
                file.write('Url è®¢é˜…å†…å®¹æ— æ³•è§£æ')
                file.close()
                print(f'Writing error of {remarks} to {ids:0>2d}.txt\n')
            elif content != None:
                content_list.append(content)
                file = open(f'{sub_list_path}{ids:0>2d}.txt', 'w', encoding= 'utf-8')
                file.write(content)
                file.close()
                print(f'Writing content of {remarks} to {ids:0>2d}.txt\n')
            else:
                file = open(f'{sub_list_path}{ids:0>2d}.txt', 'w', encoding= 'utf-8')
                file.write('Url è®¢é˜…å†…å®¹æ— æ³•è§£æ')
                file.close()
                print(f'Writing error of {remarks} to {ids:0>2d}.txt\n')

        print('Merging nodes...\n')
        content_all = ''.join(content_list) # https://python3-cookbook.readthedocs.io/zh_CN/latest/c02/p14_combine_and_concatenate_strings.html
        content_yaml = sub_convert.convert(content_all,'content','YAML',{'dup_rm_enabled': False, 'format_name_enabled': True})
        content_url = sub_convert.yaml_decode(content_yaml)
        content_base64 = sub_convert.base64_encode(content_url)
        content = content_url

        def content_write(file, output_type):
            file = open(file, 'w', encoding = 'utf-8')
            file.write(REMARKS=Openit \n ğŸš€ STATUS=èŠ‚ç‚¹æ•°é‡ï¼š____.â™¥.æ›´æ–°æ—¶é—´ï¼š________ output_type)
            file.close
        
        write_list = [f'./url', f'./long', f'{sub_merge_path}/nodes.yaml']
        content_type = (content, content_base64, content_yaml)
        for index in range(len(write_list)):
            content_write(write_list[index], content_type[index])
        print('Done!\n')

    def read_list(json_file,remote=False): # å°† sub_list.json Url å†…å®¹è¯»å–ä¸ºåˆ—è¡¨
        with open(json_file, 'r', encoding='utf-8') as f:
            raw_list = json.load(f)
        input_list = []
        for index in range(len(raw_list)):
            if raw_list[index]['enabled']:
                if remote == False:
                    urls = re.split('\|',raw_list[index]['url'])
                else:
                    urls = raw_list[index]['url']
                raw_list[index]['url'] = urls
                input_list.append(raw_list[index])
        return input_list

    def geoip_update(url):
        print('Downloading Country.mmdb...')
        try:
            request.urlretrieve(url, './utils/Country.mmdb')
            print('Success!\n')
        except Exception:
            print('Failed!\n')
            pass

    def readme_update(readme_file='./README.md', sub_list=[]): # æ›´æ–° README èŠ‚ç‚¹ä¿¡æ¯
        print('æ›´æ–° README.md ä¸­')
        with open(readme_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            f.close()
        # è·å¾—å½“å‰åå•åŠå„ä»“åº“èŠ‚ç‚¹æ•°é‡
        with open('./url', 'r', encoding='utf-8') as f:
            total = len(f.readlines())
            total = f'åˆå¹¶èŠ‚ç‚¹æ€»æ•°: `{total}`\n'
            thanks = []
            repo_amount_dic = {}
            for repo in sub_list:
                line = ''
                if repo['enabled'] == True:
                    id = repo['id']
                    remarks = repo['remarks']
                    repo_site = repo['site']

                    sub_file = f'./sub/list/{id:0>2d}.txt'
                    with open(sub_file, 'r', encoding='utf-8') as f:
                        proxies = f.readlines()
                        if proxies == ['Url è§£æé”™è¯¯'] or proxies == ['è®¢é˜…å†…å®¹è§£æé”™è¯¯']:
                            amount = 0
                        else:
                            amount = len(proxies)
                        f.close()
                    repo_amount_dic.setdefault(id, amount)
                    line = f'- [{remarks}]({repo_site}), èŠ‚ç‚¹æ•°é‡: `{amount}`\n'
                if id != 12:
                    thanks.append(line)
            f.close()
        
        # é«˜é€ŸèŠ‚ç‚¹æ‰“å°
        for index in range(len(lines)):
            if lines[index] == '### é«˜é€ŸèŠ‚ç‚¹\n': # ç›®æ ‡è¡Œå†…å®¹
                # æ¸…é™¤æ—§å†…å®¹
                lines.pop(index+1) # åˆ é™¤èŠ‚ç‚¹æ•°é‡
                while lines[index+4] != '\n':
                    lines.pop(index+4)

                with open('./Eternity', 'r', encoding='utf-8') as f:
                    proxies_base64 = f.read()
                    proxies = sub_convert.base64_decode(proxies_base64)
                    proxies = proxies.split('\n')
                    proxies = ['    '+proxy for proxy in proxies]
                    proxies = [proxy+'\n' for proxy in proxies]
                top_amount = len(proxies) - 1
                
                lines.insert(index+1, f'é«˜é€ŸèŠ‚ç‚¹æ•°é‡: `{top_amount}`\n')
                index += 4
                for i in proxies:
                    index += 1
                    lines.insert(index, i)
                break
        # æ‰€æœ‰èŠ‚ç‚¹æ‰“å°
        for index in range(len(lines)):
            if lines[index] == '### æ‰€æœ‰èŠ‚ç‚¹\n': # ç›®æ ‡è¡Œå†…å®¹
                # æ¸…é™¤æ—§å†…å®¹
                lines.pop(index+1) # åˆ é™¤èŠ‚ç‚¹æ•°é‡

                with open('./sub/sub_merge.txt', 'r', encoding='utf-8') as f:
                    proxies = f.read()
                    proxies = proxies.split('\n')
                    top_amount = len(proxies) - 1
                    f.close()
                lines.insert(index+1, f'åˆå¹¶èŠ‚ç‚¹æ€»æ•°: `{top_amount}`\n')
                """
                with open('./sub/sub_merge.txt', 'r', encoding='utf-8') as f:
                    proxies = f.read()
                    proxies = proxies.split('\n')
                    proxies = ['    '+proxy for proxy in proxies]
                    proxies = [proxy+'\n' for proxy in proxies]
                top_amount = len(proxies) - 1
                
                lines.insert(index+1, f'åˆå¹¶èŠ‚ç‚¹æ•°é‡: `{top_amount}`\n')
                
                index += 5
                for i in proxies:
                    index += 1
                    lines.insert(index, i)
                """
                break
        # èŠ‚ç‚¹æ¥æºæ‰“å°
        for index in range(len(lines)):
            if lines[index] == '### èŠ‚ç‚¹æ¥æº\n':
                # æ¸…é™¤æ—§å†…å®¹
                while lines[index+1] != '\n':
                    lines.pop(index+1)

                for i in thanks:
                    index +=1
                    lines.insert(index, i)
                break


        # å†™å…¥ README å†…å®¹
        with open(readme_file, 'w', encoding='utf-8') as f:
            data = ''.join(lines)
            print('å®Œæˆ!\n')
            f.write(data)

if __name__ == '__main__':
    update_url.update_main([0,4,5])
    sub_merge.geoip_update('https://raw.githubusercontent.com/Loyalsoldier/geoip/release/Country.mmdb')

    sub_list = sub_merge.read_list(sub_list_json)
    sub_list_remote = sub_merge.read_list(sub_list_json,True)
    sub_merge.sub_merge(sub_list_remote)
    sub_merge.readme_update(readme,sub_list)
